\section{Direct Memory Access}

\subsection{DMA main principles}

\begin{frame}
  \frametitle{DMA integration}
  DMA ({\em Direct Memory Access}) is used to copy data directly between
  devices and RAM, without going through the CPU.
  \begin{center}
    \includegraphics[height=0.7\textheight]{slides/kernel-driver-development-dma/dma-integration.pdf}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Peripheral DMA}
  Some device controllers embedded their own DMA controller
  and therefore can do DMA on their own.
  \begin{center}
    \includegraphics[height=0.7\textheight]{slides/kernel-driver-development-dma/peripheral-dma.pdf}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{DMA controllers}
  Other device controllers rely on an external DMA controller (on the
  SoC). Their drivers need to submit DMA descriptors to this controller.
  \begin{center}
    \includegraphics[height=0.7\textheight]{slides/kernel-driver-development-dma/dma-controller.pdf}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{DMA descriptors}
  DMA descriptors describe the various attributes of a DMA transfer, and are chained.
  \begin{center}
    \includegraphics[width=\textwidth]{slides/kernel-driver-development-dma/dma-descriptors.pdf}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Cache constraints}
  \begin{itemize}
  \item The CPU can access memory through a data cache
    \begin{itemize}
    \item Using the cache can be more efficient (faster accesses to
      the cache than the bus)
    \end{itemize}
  \item But the DMA does not access the CPU cache, so one needs to
    take care of cache coherency (cache content vs. memory content):
    \begin{itemize}
    \item When the CPU reads from memory accessed by DMA, the relevant
      cache lines must be invalidated to force reading from memory
      again
    \item When the CPU writes to memory before starting DMA transfers,
      the cache lines must be flushed/cleaned in order to force the data
      to reach the memory
    \end{itemize}
  \end{itemize}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{slides/kernel-driver-development-dma/caches.pdf}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{DMA addressing constraints}
  \begin{itemize}
  \item Memory and devices have physical addresses: \ksym{phys_addr_t}
  \item CPUs usually access memory through an MMU, using virtual
    pointers: \ksym{void *}
  \item DMA controllers do not access memory through the MMU and thus
    cannot manipulate virtual addresses, instead they access a
    \ksym{dma_addr_t} through either:
    \begin{itemize}
    \item physical addresses directly
    \item an IOMMU, in which case a specific mapping must be created
    \end{itemize}
  \end{itemize}
  \begin{center}
    \includegraphics[width=0.75\textwidth]{slides/kernel-driver-development-dma/addressing.pdf}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{DMA memory allocation constraints}
  The APIs must remain generic and handle all cases transparently, hence:
  \begin{itemize}
  \item Each memory chunk accessed by the DMA shall be physically
    contiguous, which means one can use:
    \begin{itemize}
    \item any memory allocated by \kfunc{kmalloc} (up to 128 KB)
    \item any memory allocated by \kfunc{__get_free_pages} (up to 8MB)
    \item block I/O and networking buffers, designed to support DMA
    \end{itemize}
  \item Unless the buffer is smaller than one page, one cannot use:
    \begin{itemize}
    \item kernel memory allocated with \kfunc{vmalloc}
    \item user memory allocated with \code{malloc()}
      \begin{itemize}
      \item Almost all the time userspace relies on the kernel to allocate
        the buffers and \kfunc{mmap} them to be usable from userspace
        (requires a dedicated user API)
      \end{itemize}
    \end{itemize}
  \end{itemize}
\end{frame}

\subsection{Kernel APIs for DMA}

\begin{frame}
  \frametitle{\code{dma-mapping} vs. \code{dmaengine} vs. \code{dma-buf}}
  The \code{dma-mapping} API:
  \begin{itemize}
  \item Allocates and manages DMA buffers
  \item Offers generic interfaces to handle coherency
  \item Manages IO-MMU DMA mappings when relevant
  \item See \kdochtml{core-api/dma-api} and
    \kdochtml{core-api/dma-api-howto}
  \end{itemize}
  The \code{dmaengine} API:
  \begin{itemize}
  \item Abstracts the DMA controller
  \item Offers generic functions to configure, queue, trigger, stop
    transfers
  \item Unused when dealing with peripheral DMA
  \item See \kdochtml{driver-api/dmaengine/client} and
  \end{itemize}
  The \code{dma-buf} API:
  \begin{itemize}
  \item Enables sharing DMA buffers between devices within the kernel
  \item Not covered in this training
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\code{dma-mapping}: Coherent or streaming DMA mappings}
  \begin{itemize}
  \item Coherent mappings
    \begin{itemize}
    \item The kernel allocates a suitable buffer and sets the mapping
      for the driver
    \item Can simultaneously be accessed by the CPU and device
    \item So, has to be in a cache coherent memory area
    \item Usually allocated for the whole time the module is loaded
      \begin{itemize}
      \item Can be expensive to setup and use on some platforms
      \item Typically implemented by disabling cache on \code{ARM}
      \end{itemize}
    \end{itemize}
  \item Streaming mappings
    \begin{itemize}
    \item Use an already allocated buffer
    \item The driver provides a buffer, the kernel just sets the mapping
    \item Mapping set up for each transfer (keeps DMA registers free on
      the hardware)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dma-mapping}: memory addressing constraints}
  \begin{itemize}
  \item The default addressing capability of the DMA controllers is
    assumed to be 32-bit.
  \item If the platform supports it, the DMA addressing capability can be:
    \begin{itemize}
    \item increased (eg. need to access highmem)
    \item decreased (eg. ISA devices, where \kfunc{kmalloc} buffers can
      also be allocated in the first part of the RAM with
      \ksym{GFP_DMA})
    \end{itemize}
  \item Linux stores this capability in a per-device mask, DMA mappings
    can fail because a buffer is out of reach
  \item In all cases, the DMA mask shall be consistent before
    allocating buffers
  \end{itemize}
\begin{minted}[fontsize=\small]{c}
int dma_set_mask_and_coherent(struct device *dev, u64 mask)
\end{minted}
  \begin{itemize}
  \item Maximum and optimal buffer sizes can also be retrieved to
    optimize allocations/buffer handling
  \end{itemize}
\begin{minted}[fontsize=\small]{c}
size_t dma_max_mapping_size(struct device *dev);
size_t dma_opt_mapping_size(struct device *dev);
\end{minted}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dma-mapping}: Allocating coherent memory mappings}
  The kernel takes care of both buffer allocation and mapping:
  \vfill
\begin{minted}[fontsize=\scriptsize]{c}
#include <linux/dma-mapping.h>

void *                       /* Output: buffer address */
    dma_alloc_coherent(
         struct device *dev, /* device structure */
         size_t size,        /* Needed buffer size in bytes */
         dma_addr_t *handle, /* Output: DMA bus address */
         gfp_t gfp           /* Standard GFP flags */
);

void dma_free_coherent(struct device *dev,
    size_t size, void *cpu_addr, dma_addr_t handle);
  \end{minted}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dma-mapping}: Setting up streaming memory mappings (single)}
  Works on already allocated buffers:
  \vfill
\begin{minted}[fontsize=\scriptsize]{c}
#include <linux/dma-mapping.h>

dma_addr_t dma_map_single(
      struct device *,        /* device structure */
      void *,                 /* input: buffer to use */
      size_t,                 /* buffer size */
      enum dma_data_direction /* Either DMA_BIDIRECTIONAL,
                               * DMA_TO_DEVICE or
                               * DMA_FROM_DEVICE */
);

void dma_unmap_single(struct device *dev, dma_addr_t handle,
    size_t size, enum dma_data_direction dir);
\end{minted}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dma-mapping}: Setting up streaming memory mappings (multiples)}
  A \code{scatterlist} using the \code{scatter-gather} library can be
  used to map several buffers and link them together
  \vfill
\begin{minted}[fontsize=\scriptsize]{c}
#include <linux/dma-mapping.h>
#include <linux/scatterlist.h>

struct scatterlist sglist[NENTS], *sg;
int i, count;

sg_init_table(sglist, NENTS);
sg_set_buf(&sglist[0], buf0, len0);
sg_set_buf(&sglist[1], buf1, len1);

count = dma_map_sg(dev, sglist, NENTS, DMA_TO_DEVICE);
for_each_sg(sglist, sg, count, i) {
        dma_address[i] = sg_dma_address(sg);
        dma_len[i] = sg_dma_len(sg);
}
...
dma_unmap_sg(dev sglist, count, DMA_TO_DEVICE);
\end{minted}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dma-mapping}: Setting up streaming I/O mappings}
  Physical addresses with MMIO registers might need to be remapped in order to
  be accessed through an IO-MMU:
  \vfill
\begin{minted}[fontsize=\scriptsize]{c}
#include <linux/dma-mapping.h>

dma_addr_t dma_map_resource(
      struct device *,         /* device structure */
      phys_addr_t,             /* input: resource to use */
      size_t,                  /* buffer size */
      enum dma_data_direction, /* Either DMA_BIDIRECTIONAL,
                                * DMA_TO_DEVICE or
                                * DMA_FROM_DEVICE */
      unsigned long attrs,     /* optional attributes */
);

void dma_unmap_resource(struct device *dev, dma_addr_t handle,
    size_t size, enum dma_data_direction dir, unsigned long attrs);
\end{minted}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dma-mapping}: Verifying DMA memory mappings}
  \begin{itemize}
  \item All mapping helpers can fail and return errors
  \item The right way to check the validity of the returned
    \ksym{dma_addr_t} is to call:
\begin{minted}[fontsize=\small]{c}
int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
\end{minted}
    \begin{itemize}
    \item May give additional clues if \ksym{CONFIG_DMA_API_DEBUG} is
      enabled.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dma-mapping}: Syncing streaming DMA mappings}
  \begin{itemize}
  \item In general streaming mappings are:
    \begin{itemize}
    \item mapped right before use with DMA
      \begin{itemize}
      \item \code{MEM_TO_DEV}: caches are flushed
      \end{itemize}
    \item unmapped right after
      \begin{itemize}
      \item \code{DEV_TO_MEM}: cache lines are invalidated
      \end{itemize}
    \end{itemize}
  \item The CPU shall only access the buffer after unmapping!
  \item If however the same memory region has to be used for several DMA
    transfers, the same mapping can be kept in place. In this case the
    data must be synchronized before access:
    \begin{itemize}
    \item The CPU needs to access the data:
\begin{minted}[fontsize=\small]{c}
dma_sync_single_for_cpu(dev, dma_handle, size, direction);
dma_sync_sg_for_cpu(dev, sglist, nents, direction);
\end{minted}
    \item The device needs to access the data:
\begin{minted}[fontsize=\small]{c}
dma_sync_single_for_device(dev, dma_handle, size, direction);
dma_sync_sg_for_device(dev, sglist, nents, direction);
\end{minted}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Starting DMA transfers}
  \begin{itemize}
  \item If the device you're writing a driver for is doing peripheral
    DMA, no external API is involved.
  \item If it relies on an external DMA controller, you'll need to
    \begin{enumerate}
    \item Ask the hardware to use DMA, so that it will drive its
      request line
    \item Use Linux \code{dmaengine} framework, especially its slave API
    \end{enumerate}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{The \code{dmaengine} framework}
  \begin{center}
    \includegraphics[width=0.9\textwidth]{slides/kernel-driver-development-dma/dmaengine-framework.pdf}
  \end{center}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dmaengine}: Slave API: Initial configuration}
  Steps to start a DMA transfer with \code{dmaengine}:
  \begin{enumerate}
  \item Request a channel for exclusive use with
    \kfunc{dma_request_chan}, or one of its variants
    \begin{itemize}
    \item This channel pointer will be used all along
    \item Returns a pointer over a \kstruct{dma_chan} which can also
      be an error pointer
    \end{itemize}
  \item Configure the engine by filling a \kstruct{dma_slave_config}
    structure and passing it to \kfunc{dmaengine_slave_config}:
  \end{enumerate}
\begin{minted}[fontsize=\scriptsize]{c}
struct dma_slave_config txconf = {};

/* Tell the engine what configuration we want on a given channel:
 * direction, access size, burst length, source and destination).
 * Source being memory, there is no buswidth or maxburst limitation
 * and each buffer will be different. */
txconf.direction = DMA_MEM_TO_DEV;
txconf.dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
txconf.dst_maxburst = TX_TRIGGER;
txconf.dst_addr = fifo_dma_addr;
ret = dmaengine_slave_config(dma->txchan, &txconf);
\end{minted}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dmaengine}: Slave API: Per-transfer configuration (1/2)}
  \begin{enumerate}
  \item Create a descriptor with all the required configuration for the
    next transfer with:
  \end{enumerate}
\begin{minted}[fontsize=\scriptsize]{c}
struct dma_async_tx_descriptor *
dmaengine_prep_slave_single(struct dma_chan *chan, dma_addr_t buf,
                            size_t len, enum dma_transfer_direction dir,
                            unsigned long flags);
struct dma_async_tx_descriptor *
dmaengine_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,
                        unsigned int sg_len, enum dma_transfer_direction dir,
                        unsigned long flags);
struct dma_async_tx_descriptor *
dmaengine_prep_dma_cyclic(struct dma_chan *chan, dma_addr_t buf, size_t buf_len,
                          size_t period_len, enum dma_data_direction dir);
\end{minted}
  \begin{itemize}
  \item A common flag is:
    \begin{itemize}
    \item \ksym{DMA_PREP_INTERRUPT}: Generates an interrupt once done
    \end{itemize}
  \item The descriptor returned can be used to fill-in a callback:
  \end{itemize}
\begin{minted}[fontsize=\scriptsize]{c}
desc->callback = foo_dma_complete;
desc->callback_param = foo_dev;
\end{minted}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\code{dmaengine}: Slave API: Per-transfer configuration (2/2)}
  \begin{enumerate}
    \setcounter{enumi}{1}
  \item Queue the next operation:
  \end{enumerate}
  \begin{minted}[fontsize=\small]{c}
dma_cookie_t cookie;

cookie = dmaengine_submit(desc);
ret = dma_submit_error(cookie);
if (ret)
   ...
\end{minted}
  \begin{enumerate}
    \setcounter{enumi}{2}
  \item Trigger the queued transfers
  \end{enumerate}
  \begin{minted}[fontsize=\small]{c}
dma_async_issue_pending(chan);
\end{minted}
  \begin{enumerate}
  \item[3bis.] In case anything went wrong or the device should stop being
    used, it is possible to terminate all ongoing transactions with:
  \end{enumerate}
  \begin{minted}[fontsize=\small]{c}
dmaengine_terminate_sync(chan);
\end{minted}
\end{frame}

\begin{frame}
  \frametitle{Examples}
  \begin{itemize}
  \item Commented network driver, whith both streaming and coherent
    mappings:\\
    \small \url{https://bootlin.com/pub/drivers/r6040-network-driver-with-comments.c}
  \item Example of usage of the slave API: look at the code for
    \kfunc{stm32_i2c_prep_dma_xfer}.
  \end{itemize}
\end{frame}

\setuplabframe
{DMA}
{
  \begin{itemize}
  \item Setup streaming mappings with the \code{dma-mapping} API
  \item Configure a DMA controller with the \code{dmaengine} API
  \item Configure the hardware to trigger DMA transfers
  \item Wait for DMA completion
  \end{itemize}
}
